{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过Numpy数组来生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过已有的张量来生成新的张量\n",
    "新的张量将继承已有张量的数据属性(结构、类型), 也可以重新指定新的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "x_rand tensor: \n",
      "tensor([[0.0701, 0.3303],\n",
      "        [0.4778, 0.8198]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"ones tensor: \\n{x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float32)\n",
    "print(f\"x_rand tensor: \\n{x_rand} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过指定数据维度来生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random tensor:\n",
      " tensor([[0.5297, 0.2207, 0.4695],\n",
      "        [0.3164, 0.0594, 0.0994]])\n",
      "\n",
      "ones tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "zeros tensor:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor =  torch.zeros(shape)\n",
    "\n",
    "print(f\"random tensor:\\n {rand_tensor}\\n\")\n",
    "print(f\"ones tensor:\\n {ones_tensor}\\n\")\n",
    "print(f\"zeros tensor:\\n {zeros_tensor}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor data: tensor([[0.9235, 0.3224, 0.4875, 0.1161],\n",
      "        [0.2045, 0.4898, 0.1466, 0.8452],\n",
      "        [0.5143, 0.6199, 0.1340, 0.6412]])\n",
      "tensor shape: torch.Size([3, 4])\n",
      "dtype : torch.float32\n",
      "device tensor in stored on:cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f\"tensor data: {tensor}\")\n",
    "print(f\"tensor shape: {tensor.shape}\")\n",
    "print(f\"dtype : {tensor.dtype}\")\n",
    "print(f\"device tensor in stored on:{tensor.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量运算\n",
    "判断是否可以在GPU上执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "print(tensor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0  # 将第1列(从0开始)的数据全部赋值为0\n",
    "print(tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([12, 4])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor,tensor,tensor])\n",
    "print(tensor.shape)\n",
    "print(t1.shape)\n",
    "print(t1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数stack()对序列数据内部的张量进行扩维拼接，指定维度由程序员选择、大小是生成后数据的维度区间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 20, 30],\n",
      "         [40, 50, 60],\n",
      "         [70, 80, 90]]])\n",
      "torch.Size([3, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [10, 20, 30]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [40, 50, 60]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [70, 80, 90]]])\n",
      "torch.Size([3, 3, 2])\n",
      "tensor([[[ 1, 10],\n",
      "         [ 2, 20],\n",
      "         [ 3, 30]],\n",
      "\n",
      "        [[ 4, 40],\n",
      "         [ 5, 50],\n",
      "         [ 6, 60]],\n",
      "\n",
      "        [[ 7, 70],\n",
      "         [ 8, 80],\n",
      "         [ 9, 90]]])\n"
     ]
    }
   ],
   "source": [
    "T1 = torch.tensor([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "# 假设是时间步T2\n",
    "T2 = torch.tensor([[10, 20, 30],\n",
    "                [40, 50, 60],\n",
    "                [70, 80, 90]])\n",
    "\n",
    "print(T1.shape)\n",
    "print(T2.shape)\n",
    "\n",
    "print(torch.stack((T1,T2),dim=0).shape)\n",
    "print(torch.stack((T1,T2),dim=0))\n",
    "\n",
    "\n",
    "print(torch.stack((T1,T2),dim=1).shape)\n",
    "print(torch.stack((T1,T2),dim=1))\n",
    "\n",
    "print(torch.stack((T1,T2),dim=2).shape)\n",
    "print(torch.stack((T1,T2),dim=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的乘积和矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor.mul(tensor):\n",
      "tensor([[ 1,  4,  9],\n",
      "        [16, 25, 36]])\n",
      "\n",
      "tensor * tensor: \n",
      " tensor([[ 1,  4,  9],\n",
      "        [16, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "print(tensor)\n",
    "tensor_1 = copy.deepcopy(tensor)\n",
    "tensor_2 = copy.deepcopy(tensor)\n",
    "#逐个元素相乘结果\n",
    "print(f\"tensor.mul(tensor):\\n{tensor_1.mul(tensor_2)}\\n\")\n",
    "# 等价写法:\n",
    "print(f\"tensor * tensor: \\n {tensor_1 * tensor_2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面写法表示张量与张量的矩阵乘法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T): \n",
      " tensor([[14, 32],\n",
      "        [32, 77]]) \n",
      "\n",
      "tensor @ tensor.T: \n",
      " tensor([[14, 32],\n",
      "        [32, 77]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"tensor.matmul(tensor.T): \\n {tensor_1.matmul(tensor_1.T)} \\n\")\n",
    "# 等价写法:\n",
    "print(f\"tensor @ tensor.T: \\n {tensor_1 @ tensor_1.T}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 自动赋值运算\n",
    " 自动赋值运算通常在方法后有 _ 作为后缀, 例如: x.copy_(y), x.t_()操作会改变 x 的取值。\n",
    " 自动赋值运算虽然可以节省内存, 但在求导时会因为丢失了中间过程而导致一些问题, 所以我们并不鼓励使用它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[ 5,  6,  7],\n",
      "        [ 8,  9, 10]])\n",
      "tensor([[ 5,  6,  7],\n",
      "        [ 8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1)\n",
    "\n",
    "print(tensor_1.add_(4))\n",
    "print(tensor_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor与Numpy的转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r:tensor([1., 1., 1., 1., 1.])\n",
      "n:[1. 1. 1. 1. 1.]\n",
      "n:[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"r:{t}\")\n",
    "n= t.numpy()\n",
    "print(f\"n:{n}\")\n",
    "# 修改张量的值，则Numpy array数组值也会随之改变。\n",
    "t.add_(2)\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由Numpy array数组转为张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "t:tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones([5,3])\n",
    "t= torch.from_numpy(n)\n",
    "print(f\"t:{t}\")\n",
    "np.add(n, 2, out=n)\n",
    "print(f\"t:{t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2f124e168085d4addd4d92786f74a9c033bbbe29627264b3eb334e13afab902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
